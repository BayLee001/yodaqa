<?xml version="1.0" encoding="UTF-8" ?>
  <typeSystemDescription xmlns="http://uima.apache.org/resourceSpecifier">
    <name>CandidateAnswerTypes</name>
    <description>CandidateAnswerCAS type system</description>
    <vendor>yodaqa</vendor>
    <version>1.0</version>
    <types>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerInfo</name>
        <description>Meta-information on the generated candidate answer</description>
        <supertypeName>uima.cas.TOP</supertypeName>
        <features>
          <featureDescription>
            <name>canonText</name>
	    <description>Syntactically canonical form of the answer (without leading/trailing interpunction and the- and such)</description>
            <rangeTypeName>uima.cas.String</rangeTypeName>
          </featureDescription>
          <featureDescription>
            <name>features</name>
            <description>A set of features of this answer. Unmatched features should simply not be present, and order does not matter. Duplicates should NOT appear.</description>
            <rangeTypeName>uima.cas.FSArray</rangeTypeName>
            <elementType>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</elementType>
          </featureDescription>
          <featureDescription>
            <name>isLast</name>
            <description>Whether this is the last candidate answer CAS</description>
            <rangeTypeName>uima.cas.Boolean</rangeTypeName>
          </featureDescription>
        </features>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.PassageForParsing</name>
        <description>A passage on which a parser should be run</description>
        <supertypeName>uima.tcas.Annotation</supertypeName>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</name>
        <description>A feature matched on this answer. This type is for sub-classing to particular features.</description>
        <supertypeName>uima.cas.TOP</supertypeName>
        <features>
          <featureDescription>
            <name>value</name>
            <description>Feature value. Unmatched features are assumed 0. Ideally, the feature value should be in the interval of [0,1], but this is not enforced.</description>
            <rangeTypeName>uima.cas.Double</rangeTypeName>
          </featureDescription>
        </features>
      </typeDescription>
      <!-- N.B. for the time being, new types must be also added to a list in
           src/main/java/cz/brmlab/yodaqa/analysis/answer/AnswerFV.java -->
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Occurences</name>
        <description>Answer Feature: Number of times this answer has been generated</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ResultLogScore</name>
        <description>Answer Feature: Log-score (by solr) of the result that produced the supporting passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PassageLogScore</name>
        <description>Answer Feature: Log-score of the passage that produced this answer</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsg</name>
        <description>Answer Feature: 1 if the origin of this answer is an in-document passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgFirst</name>
        <description>Answer Feature: 1 if the origin of this answer is the first passage of document (often a blurb packed with is-a relationships information)</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNP</name>
        <description>Answer Feature: 1 if the origin of this answer is a noun phrase parsed in a passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNE</name>
        <description>Answer Feature: 1 if the origin of this answer is a named entity matched in a passage (TODO: also distinguish the type of matched named entity?)</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNPByLATSubj</name>
	<description>Answer Feature: 1 if the origin of this answer is a noun phrase parsed in a passage that is object of a subject that matches question LAT ("What is critical mass of X?" -> "Critical mass is ***")</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgSurprise</name>
	<description>Answer Feature: 1 if the origin of this answer is a passage that does not end with a question clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDocTitle</name>
        <description>Answer Feature: 1 if the origin of this answer is a document title</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRelation</name>
        <description>Answer Feature: 1 if the origin of this answer is a DBpedia property.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConcept</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptBySubject</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question subject clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptByLAT</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question focus clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptByNE</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question NamedEntity clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginMultiple</name>
        <description>Answer Feature: 1 if this answer was generated by multiple orthogonal annotators.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SpWordNet</name>
        <description>Answer Feature: Specificity measured as WordNet graph exp(-distance), i.e. 1 is perfect match, 1/e is very specific, ..., 1/e^4 is already very non-specific</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQNoWordNet</name>
        <description>Answer Feature: Question LAT has no derivable WordNet LATs.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATANoWordNet</name>
        <description>Answer Feature: Answer LAT has no derivable WordNet LATs.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorSpQHit</name>
        <description>Answer Feature: Question LAT is direct hypernyme of the answer LAT.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorSpAHit</name>
        <description>Answer Feature: Answer LAT is direct hypernyme of the question LAT.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorANE</name>
        <description>Answer Feature: Matched answer LAT has been generated by answer named entity type.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorADBp</name>
        <description>Answer Feature: Matched answer LAT has been generated by DBpedia rdf:type of the concept.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAQuantity</name>
        <description>Answer Feature: Matched answer LAT has been generated by quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAQuantityCD</name>
        <description>Answer Feature: Matched answer LAT has been generated by numerical quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAWnInstance</name>
        <description>Answer Feature: Matched answer LAT has been generated by Wordnet instance-of relation to the concept in focus.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorADBpRelation</name>
        <description>Answer Feature: Matched answer LAT has been generated by a DBpedia property.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageSp</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value carries the specificity of the question LAT, weighed by the word exp-inverse-distance from the answer (see below).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageDist</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value carries exp-inverse-distance in characters between the LAT word and the answer segment, with 1 being that the LAT is one of the answer words or just nearby.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageInside</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value is 1.0 if the LAT word match is actually within the answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SimpleScore</name>
        <description>Answer Feature: A score as determined by our good old original simple scoring routine that uses just a handful of naive features.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATNE</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is the kind of named entity recognized.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATDBpType</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is the kind of named entity recognized.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQuantity</name>
        <description>Answer Feature: Boolean value whether we generated a LAT based on seeing a quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQuantityCD</name>
        <description>Answer Feature: Boolean value whether we generated a LAT based on seeing a concrete numeric quantity.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATWnInstance</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is the other side of a Wordnet instance-of relation.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATDBpRelation</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is a DBpedia property name.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_MergedSyntaxScore</name>
        <description>Answer Feature: Sum of scores of all answers that were merged into this one because they were syntactically equivalent.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TopAnswer</name>
        <description>Answer Feature: Boolean value whether we are one of the top answers selected by earlier scoring.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for question + answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrAHitsEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsANormEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for question + answer, normalized by number of search hits for just the answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrMaxScoreEv</name>
        <description>Answer Feature: Unbounded float representing the maximum score among search hits for question + answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsMaxScoreEv</name>
        <description>Answer Feature: Unbounded float representing SolrHitsEv * SolrMaxScoreEv.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Phase0Score</name>
        <description>Answer Feature: Confidence computed in phase 0 (for use by next phases).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Phase1Score</name>
        <description>Answer Feature: Confidence computed in phase 1 (for use by next phases).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
    </types>
  </typeSystemDescription>
